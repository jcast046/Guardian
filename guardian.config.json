{
  "models": {
    "summarizer_instruct": "models/Qwen2.5-3B-Instruct",
    "extractor_instruct": "models/Qwen2.5-3B-Instruct",
    "weak_labeler_instruct": "models/Qwen2.5-3B-Instruct"
  },
  "use_llama_as_extractor": false,
  "quantize_4bit": true,
  "device": "cuda",
  "dtype": "bfloat16",
  "batch_size": 16,
  "max_new_tokens": 256
}





